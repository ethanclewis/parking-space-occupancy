{"cells":[{"cell_type":"markdown","metadata":{"id":"j79WXaM0UssD"},"source":["# Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":765,"status":"ok","timestamp":1654105962192,"user":{"displayName":"Martin Marek","userId":"04932572550491068578"},"user_tz":-60},"id":"i8SWjZbURLPV"},"outputs":[],"source":["import os\n","import io\n","import json\n","import requests\n","import zipfile\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","\n","from collections import defaultdict\n","from collections import namedtuple\n","from glob import glob"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Adjust CWD\n","directory = os.getcwd().replace('\\\\notebooks', '')\n","os.chdir(directory)\n","wd = os.getcwd()"]},{"cell_type":"markdown","metadata":{},"source":["# Baseline Results"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["FasterRCNN_FPN_1100_square: 5\n","FasterRCNN_FPN_800_square: 5\n","RCNN_128_square: 5\n","RCNN_64_square: 5\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Validation Accuracy %</th>\n","      <th>Testing Accuracy %</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FasterRCNN_FPN_1100_square</td>\n","      <td>98.540 ± 0.115</td>\n","      <td>98.523489 ± 0.113897</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FasterRCNN_FPN_800_square</td>\n","      <td>98.362 ± 0.067</td>\n","      <td>98.308723 ± 0.083610</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>RCNN_128_square</td>\n","      <td>98.382 ± 0.062</td>\n","      <td>97.973155 ± 0.074494</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>RCNN_64_square</td>\n","      <td>97.996 ± 0.080</td>\n","      <td>97.731544 ± 0.125055</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Model Name Validation Accuracy %    Testing Accuracy %\n","0  FasterRCNN_FPN_1100_square        98.540 ± 0.115  98.523489 ± 0.113897\n","1   FasterRCNN_FPN_800_square        98.362 ± 0.067  98.308723 ± 0.083610\n","2             RCNN_128_square        98.382 ± 0.062  97.973155 ± 0.074494\n","3              RCNN_64_square        97.996 ± 0.080  97.731544 ± 0.125055"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# create model validation and test accuracy storage\n","va_dict = defaultdict(list)\n","ta_dict = defaultdict(list)\n","\n","# iterate through model directories\n","for model_dir in sorted(glob(f'training_logs\\\\baseline/*')):\n","    \n","    # get model id based on model directory\n","    _, model_id = os.path.split(model_dir) #altered as original code included \"training_output\\\" in model names\n","    \n","    # split model_id into model_name and training_iter\n","    model_name, _ = model_id.rsplit('_', 1)\n","    \n","    # read validation accuracy from training logs \n","    train_log = pd.read_csv(f'{model_dir}/train_log.csv')\n","    va = train_log.valid_accuracy.tolist()\n","    \n","    # append validation and test accuracy to corresponding list\n","    # append logs if they're the first logs of the given model\n","    # or if they're of the same length as the previous logs\n","    # (avoid storing logs of a model that hasn't finished trainig yet) \n","    if len(va_dict[model_name]) == 0 or len(va_dict[model_name][0]) == len(va):\n","        # read test accuracy from test logs\n","        with open(f'{model_dir}/test_logs.json') as f:\n","            ta = json.load(f)['accuracy']\n","            \n","        va_dict[model_name] += [va]\n","        ta_dict[model_name] += [ta]\n","\n","# compute accuracy mean and SE for each model\n","Logs = namedtuple('Logs', ['va_mean', 'va_se', 'ta_mean', 'ta_se'])\n","logs = {}\n","for k, v in va_dict.items():\n","    # print number of training iters for each model\n","    print(f'{k}: {len(v)}')\n","\n","    # calculate the mean and standard error of valid. accuracy\n","    va = np.array(v)\n","    # va = np.array([ma(x, 10) for x in va])\n","    va_mean = np.mean(va, 0)\n","    va_se = np.std(va, 0) / np.sqrt(va.shape[0])\n","    \n","    # calculate the mean and standard error of test accuracy\n","    ta = np.array(ta_dict[k])\n","    ta_mean = np.mean(ta)\n","    ta_se = np.std(ta) / np.sqrt(len(ta))\n","    \n","    # save validation and test logs\n","    logs[k] = Logs(va_mean, va_se, ta_mean, ta_se)\n","\n","# Initialize lists to store data\n","model_names = []\n","validation_accuracy = []\n","testing_accuracy = []\n","\n","# Iterate over the logs\n","for var, log in logs.items():\n","    # Extract mean and standard error for validation accuracy\n","    va_mean = log.va_mean[-1]\n","    va_se = log.va_se[-1]\n","    \n","    # Extract mean and standard error for testing accuracy\n","    ta_mean = log.ta_mean\n","    ta_se = log.ta_se\n","    \n","    # Append data to lists\n","    model_names.append(f'{var}')\n","    validation_accuracy.append(f'{100 * va_mean:.3f} ± {100 * va_se:.3f}')\n","    testing_accuracy.append(f'{100 * ta_mean:.6f} ± {100 * ta_se:.6f}')\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'Model Name': model_names,\n","    'Validation Accuracy %': validation_accuracy,\n","    'Testing Accuracy %': testing_accuracy\n","})\n","\n","# Display DataFrame\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# Enhanced Results"]},{"cell_type":"markdown","metadata":{},"source":["## Choose Augmentation Method"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["logs_dir = 'training_logs\\\\random_se_b'\n","#logs_dir = 'training_logs\\\\proportional_se_b'"]},{"cell_type":"markdown","metadata":{"id":"qXrfLdnwRLPX"},"source":["## Load Model Training Logs"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["FasterRCNN_FPN_1100_var1.5: 5\n","FasterRCNN_FPN_1100_var1.75: 5\n","FasterRCNN_FPN_1100_var2.0: 5\n","FasterRCNN_FPN_800_var1.5: 5\n","FasterRCNN_FPN_800_var1.75: 5\n","FasterRCNN_FPN_800_var2.0: 5\n","RCNN_128_var1.5: 5\n","RCNN_128_var1.75: 5\n","RCNN_128_var2.0: 5\n","RCNN_64_var1.5: 5\n","RCNN_64_var1.75: 5\n","RCNN_64_var2.0: 5\n"]}],"source":["# create model validation and test accuracy storage\n","va_dict = defaultdict(list)\n","ta_dict = defaultdict(list)\n","\n","# iterate through model directories\n","for model_dir in sorted(glob(f'{logs_dir}/*')):\n","    \n","    # get model id based on model directory\n","    _, model_id = os.path.split(model_dir)\n","    \n","    # extract model_name and var from model_id\n","    model_name, var = model_id.rsplit('_', 1)\n","    \n","    # remove the \"_square_X\" portion from model_name\n","    model_name = model_name.split('_square')[0]\n","    \n","    # append validation and test accuracy to corresponding list\n","    # read validation accuracy from training logs \n","    train_log = pd.read_csv(f'{model_dir}/train_log.csv')\n","    va = train_log.valid_accuracy.tolist()\n","    va_dict[f'{model_name}_{var}'].append(va)\n","    \n","    # read test accuracy from test logs\n","    with open(f'{model_dir}/test_logs.json') as f:\n","        ta = json.load(f)['accuracy']\n","    ta_dict[f'{model_name}_{var}'].append(ta)\n","\n","# compute accuracy mean and SE for each model\n","Logs = namedtuple('Logs', ['va_mean', 'va_se', 'ta_mean', 'ta_se'])\n","logs = {}\n","for model_id, v in va_dict.items():\n","    # print number of training iters for each model\n","    print(f'{model_id}: {len(v)}')\n","\n","    # calculate the mean and standard error of valid. accuracy\n","    va = np.array(v)\n","    va_mean = np.mean(va, axis=0)\n","    va_se = np.std(va, axis=0) / np.sqrt(va.shape[0])\n","    \n","    # calculate the mean and standard error of test accuracy\n","    ta = np.array(ta_dict[model_id])\n","    ta_mean = np.mean(ta)\n","    ta_se = np.std(ta) / np.sqrt(len(ta))\n","    \n","    # save validation and test logs\n","    logs[model_id] = Logs(va_mean, va_se, ta_mean, ta_se)"]},{"cell_type":"markdown","metadata":{"id":"zPmGS2c4RLPa"},"source":["## Display Results"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model Name</th>\n","      <th>Validation Accuracy %</th>\n","      <th>Testing Accuracy %</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FasterRCNN_FPN_1100_var1.5</td>\n","      <td>98.646 ± 0.028</td>\n","      <td>98.496644 ± 0.077341</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FasterRCNN_FPN_1100_var1.75</td>\n","      <td>98.824 ± 0.056</td>\n","      <td>98.510067 ± 0.058200</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FasterRCNN_FPN_1100_var2.0</td>\n","      <td>98.738 ± 0.093</td>\n","      <td>98.563758 ± 0.055668</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FasterRCNN_FPN_800_var1.5</td>\n","      <td>98.498 ± 0.038</td>\n","      <td>98.268455 ± 0.051639</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FasterRCNN_FPN_800_var1.75</td>\n","      <td>98.518 ± 0.129</td>\n","      <td>98.174497 ± 0.091826</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>FasterRCNN_FPN_800_var2.0</td>\n","      <td>98.348 ± 0.105</td>\n","      <td>98.268456 ± 0.074494</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>RCNN_128_var1.5</td>\n","      <td>98.476 ± 0.099</td>\n","      <td>98.040270 ± 0.039818</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RCNN_128_var1.75</td>\n","      <td>98.508 ± 0.066</td>\n","      <td>98.174496 ± 0.058200</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>RCNN_128_var2.0</td>\n","      <td>98.540 ± 0.077</td>\n","      <td>98.067114 ± 0.087814</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>RCNN_64_var1.5</td>\n","      <td>98.362 ± 0.051</td>\n","      <td>98.214765 ± 0.055668</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>RCNN_64_var1.75</td>\n","      <td>98.308 ± 0.077</td>\n","      <td>98.093960 ± 0.101518</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>RCNN_64_var2.0</td>\n","      <td>98.446 ± 0.112</td>\n","      <td>98.161073 ± 0.070005</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     Model Name Validation Accuracy %    Testing Accuracy %\n","0    FasterRCNN_FPN_1100_var1.5        98.646 ± 0.028  98.496644 ± 0.077341\n","1   FasterRCNN_FPN_1100_var1.75        98.824 ± 0.056  98.510067 ± 0.058200\n","2    FasterRCNN_FPN_1100_var2.0        98.738 ± 0.093  98.563758 ± 0.055668\n","3     FasterRCNN_FPN_800_var1.5        98.498 ± 0.038  98.268455 ± 0.051639\n","4    FasterRCNN_FPN_800_var1.75        98.518 ± 0.129  98.174497 ± 0.091826\n","5     FasterRCNN_FPN_800_var2.0        98.348 ± 0.105  98.268456 ± 0.074494\n","6               RCNN_128_var1.5        98.476 ± 0.099  98.040270 ± 0.039818\n","7              RCNN_128_var1.75        98.508 ± 0.066  98.174496 ± 0.058200\n","8               RCNN_128_var2.0        98.540 ± 0.077  98.067114 ± 0.087814\n","9                RCNN_64_var1.5        98.362 ± 0.051  98.214765 ± 0.055668\n","10              RCNN_64_var1.75        98.308 ± 0.077  98.093960 ± 0.101518\n","11               RCNN_64_var2.0        98.446 ± 0.112  98.161073 ± 0.070005"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize lists to store data\n","model_names = []\n","validation_accuracy = []\n","testing_accuracy = []\n","\n","# Iterate over the logs\n","for var, log in logs.items():\n","    # Extract mean and standard error for validation accuracy\n","    va_mean = log.va_mean[-1]\n","    va_se = log.va_se[-1]\n","    \n","    # Extract mean and standard error for testing accuracy\n","    ta_mean = log.ta_mean\n","    ta_se = log.ta_se\n","    \n","    # Append data to lists\n","    model_names.append(f'{var}')\n","    validation_accuracy.append(f'{100 * va_mean:.3f} ± {100 * va_se:.3f}')\n","    testing_accuracy.append(f'{100 * ta_mean:.6f} ± {100 * ta_se:.6f}')\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'Model Name': model_names,\n","    'Validation Accuracy %': validation_accuracy,\n","    'Testing Accuracy %': testing_accuracy\n","})\n","\n","# Display DataFrame\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"train_log_analysis.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
