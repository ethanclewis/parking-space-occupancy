{"cells":[{"cell_type":"markdown","metadata":{"id":"j79WXaM0UssD"},"source":["# Environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":765,"status":"ok","timestamp":1654105962192,"user":{"displayName":"Martin Marek","userId":"04932572550491068578"},"user_tz":-60},"id":"i8SWjZbURLPV"},"outputs":[],"source":["import os\n","import io\n","import json\n","import requests\n","import zipfile\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","\n","from collections import defaultdict\n","from collections import namedtuple\n","from glob import glob"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Adjust CWD\n","directory = os.getcwd().replace('\\\\notebooks', '')\n","os.chdir(directory)\n","wd = os.getcwd()"]},{"cell_type":"markdown","metadata":{},"source":["# Choose Model Results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logs_dir = 'baseline'\n","#logs_dir = 'random_se_b'\n","#logs_dir = 'proportional_se_b'"]},{"cell_type":"markdown","metadata":{"id":"qXrfLdnwRLPX"},"source":["# Load Model Training Logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1627244448865,"user":{"displayName":"Martin Marek","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhPMe9bH4uZG5V-exmgiiZJtm58T0EKUuVCQ0ONxck=s64","userId":"04932572550491068578"},"user_tz":-60},"id":"iXKahUnhRLPY","outputId":"64ced97d-6070-4067-8390-954d1197a4eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["FasterRCNN_FPN_1100_qdrl: 5\n","FasterRCNN_FPN_1100_square: 5\n","FasterRCNN_FPN_1440_qdrl: 5\n","FasterRCNN_FPN_1440_square: 5\n","FasterRCNN_FPN_800_qdrl: 5\n","FasterRCNN_FPN_800_square: 5\n","RCNN_128_qdrl: 5\n","RCNN_128_square: 5\n","RCNN_256_qdrl: 5\n","RCNN_256_square: 5\n","RCNN_64_qdrl: 5\n","RCNN_64_square: 5\n"]}],"source":["# create model validation and test accuracy storage\n","va_dict = defaultdict(list)\n","ta_dict = defaultdict(list)\n","\n","# iterate through model directories\n","for model_dir in sorted(glob(f'{logs_dir}/*')):\n","    \n","    # get model id based on model directory\n","    _, model_id = os.path.split(model_dir)\n","    \n","    # extract model_name and var from model_id\n","    model_name, var = model_id.rsplit('_', 1)\n","    model_name = model_name.rsplit('_', 1)[0]  # remove the extra part\n","    \n","    # append validation and test accuracy to corresponding list\n","    # read validation accuracy from training logs \n","    train_log = pd.read_csv(f'{model_dir}/train_log.csv')\n","    va = train_log.valid_accuracy.tolist()\n","    va_dict[var].append(va)\n","    \n","    # read test accuracy from test logs\n","    with open(f'{model_dir}/test_logs.json') as f:\n","        ta = json.load(f)['accuracy']\n","    ta_dict[var].append(ta)\n","\n","# compute accuracy mean and SE for each model\n","Logs = namedtuple('Logs', ['va_mean', 'va_se', 'ta_mean', 'ta_se'])\n","logs = {}\n","for var, v in va_dict.items():\n","    # print number of training iters for each model\n","    print(f'{model_name}_{var}: {len(v)}')\n","\n","    # calculate the mean and standard error of valid. accuracy\n","    va = np.array(v)\n","    va_mean = np.mean(va, axis=0)\n","    va_se = np.std(va, axis=0) / np.sqrt(va.shape[0])\n","    \n","    # calculate the mean and standard error of test accuracy\n","    ta = np.array(ta_dict[var])\n","    ta_mean = np.mean(ta)\n","    ta_se = np.std(ta) / np.sqrt(len(ta))\n","    \n","    # save validation and test logs\n","    logs[var] = Logs(va_mean, va_se, ta_mean, ta_se)\n"]},{"cell_type":"markdown","metadata":{"id":"zPmGS2c4RLPa"},"source":["# Compare models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize lists to store data\n","model_names = []\n","validation_accuracy = []\n","testing_accuracy = []\n","\n","# Iterate over the logs\n","for var, log in logs.items():\n","    # Extract mean and standard error for validation accuracy\n","    va_mean = log.va_mean[-1]\n","    va_se = log.va_se[-1]\n","    \n","    # Extract mean and standard error for testing accuracy\n","    ta_mean = log.ta_mean\n","    ta_se = log.ta_se\n","    \n","    # Append data to lists\n","    model_names.append(f'{model_name}_{var}')\n","    validation_accuracy.append(f'{100 * va_mean:.3f} ± {100 * va_se:.3f}')\n","    testing_accuracy.append(f'{100 * ta_mean:.6f} ± {100 * ta_se:.6f}')\n","\n","# Create DataFrame\n","df = pd.DataFrame({\n","    'Model Name': model_names,\n","    'Validation Accuracy %': validation_accuracy,\n","    'Testing Accuracy %': testing_accuracy\n","})\n","\n","# Display DataFrame\n","df"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"train_log_analysis.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
